{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ca0f55e",
   "metadata": {},
   "source": [
    "<h3> Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "456cab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Data \n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af4265a",
   "metadata": {},
   "source": [
    "<h1> Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7188689",
   "metadata": {},
   "outputs": [],
   "source": [
    "class h5Dataset(Dataset):\n",
    "    def __init__(self, h5_path):\n",
    "        self.h5_path = h5_path\n",
    "\n",
    "        with h5py.File(self.h5_path, \"r\") as f:\n",
    "            self.keys = list(f.keys())\n",
    "\n",
    "        self._edge_cache = {} # cache for fully connected edges to improve performance\n",
    "        self._f = None  # open file once \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # --- open file ---\n",
    "        f = self._get_file()\n",
    "\n",
    "        # --- load sample ---\n",
    "        sample = f[self.keys[index]]\n",
    "\n",
    "        # --- load and cast raw features from sample ---\n",
    "        csm = torch.from_numpy(sample[\"csm\"][:]).squeeze().to(torch.complex64) # (N, N), complex64\n",
    "        eigmode = torch.from_numpy(sample[\"eigmode\"][:]).to(torch.complex64) # (N, N), complex64\n",
    "        eigmode = torch.view_as_real(eigmode).to(torch.float32)  \n",
    "        coords = torch.from_numpy(sample[\"cartesian_coordinates\"][:]).T.to(torch.float32) # (N, 3), float32 \n",
    "        loc = torch.from_numpy(sample[\"loc\"][:]).to(torch.float32) # (3, nsources), float32\n",
    "        source_strength = torch.from_numpy(sample[\"source_strength_analytic\"][:]).squeeze(0).to(torch.float32) # (nsources,), float32\n",
    "\n",
    "\n",
    "        # --- normalize raw features ---\n",
    "        #TODO: check alternative approach normalize autopower by trace and cross spectra by coherence\n",
    "        csm = csm / torch.trace(csm).real\n",
    "        source_strength = source_strength / source_strength.sum()\n",
    "\n",
    "        # --- define node features ---        \n",
    "        theta = torch.atan2(coords[:, 1], coords[:, 0])\n",
    "        cos_theta = torch.cos(theta) # (N,), float32\n",
    "        sin_theta = torch.sin(theta) # (N,), float32\n",
    "\n",
    "        r = torch.sqrt(coords[:, 0]**2 + coords[:, 1]**2) # (N,), float32\n",
    "        r = r / (r.max() + 1e-8) # normalize radius  \n",
    "        \n",
    "        autopower = torch.diagonal(csm) # (N,), complex64\n",
    "        autopower_real = autopower.real # (N,), float32\n",
    "        autopower_imag = autopower.imag # (N,), float32\n",
    "\n",
    "        #TODO: implement positional encoding (Min-Sang Baek, Joon-Hyuk Chang, and Israel Cohen) \n",
    " \n",
    "        # --- define adjacency--- \n",
    "        N = coords.size(0)\n",
    "        edge_index = self.get_fully_connected_edges(N)   # (2, E), cached, no self-loops\n",
    "\n",
    "        src, dst = edge_index  # (E,), (E,)\n",
    "\n",
    "        # --- define edge features ---\n",
    "        cross_spectra = csm[src, dst]  # (E, 1), complex64\n",
    "        cross_spectra_real = cross_spectra.real # (E, 1), float32\n",
    "        cross_spectra_imag = cross_spectra.imag # (E, 1), float32\n",
    "\n",
    "        dx = (coords[dst, 0] - coords[src, 0])\n",
    "        dy = (coords[dst, 1] - coords[src, 1])   \n",
    "        dist = torch.sqrt(dx**2 + dy**2 + 1e-8) # (E, 1), float32\n",
    "        \n",
    "        unit_direction_x = dx / dist # (E, 1), float32 \n",
    "        unit_direction_y = dy / dist # (E, 1), float32\n",
    "\n",
    "        cos_sim = (cos_theta[src] * cos_theta[dst] + sin_theta[src] * sin_theta[dst]) # (E, 1), float32, computed with trigonometric identity\n",
    "\n",
    "        #TODO: implement directional features (Jingjie Fan, Rongzhi Gu, Yi Luo, and Cong Pang)\n",
    "\n",
    "\n",
    "        # --- build feature vectors ---\n",
    "        node_feat = self.build_feature(coords, r, cos_theta, sin_theta, autopower_real, autopower_imag, dim=1) # (N, F_node)\n",
    "        edge_attr = self.build_feature(cross_spectra_real,cross_spectra_imag, dist, unit_direction_x, unit_direction_y, cos_sim, dim=1)  # (E, F_edge)\n",
    "\n",
    "        # ---  define eigmode tokens analog to Kujawaski et. al---\n",
    "        eigmode = torch.cat([torch.cat([eigmode[..., 0], -eigmode[..., 1]], dim=-1), torch.cat([eigmode[..., 1],  eigmode[..., 0]], dim=-1),],dim=-2,)\n",
    "\n",
    "        # --- labels ---\n",
    "        loc_strongest_source = loc[:,torch.argmax(source_strength)]\n",
    "        loc_strongest_source = loc_strongest_source[:2].unsqueeze(0) #x and y coordinates only\n",
    "\n",
    "        strength_strongest_source = source_strength[torch.argmax(source_strength)] \n",
    "\n",
    "        # --- build PyG Data ---\n",
    "        data = Data(\n",
    "            x=node_feat,                 # (N, F_node)\n",
    "            edge_index=edge_index,       # (2, E)\n",
    "            edge_attr=edge_attr,         # (E, F_edge)\n",
    "            #TODO: Change to multiple sources and strengths later on\n",
    "            y=loc_strongest_source,      # label used by training loop\n",
    "        )\n",
    "\n",
    "        data.eigmode = eigmode\n",
    "\n",
    "        return data.y\n",
    "    \n",
    "\n",
    "    #--- utility functions ---\n",
    "    @staticmethod\n",
    "    def build_feature(*feats, dim=-1):\n",
    "        \"\"\"\n",
    "        Utility function to construct a feature tensor from multiple inputs.\n",
    "\n",
    "        If a tensor is 1D (shape: [N]), it is automatically expanded to\n",
    "        shape [N, 1] so that it can be concatenated with higher-dimensional\n",
    "        feature tensors.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        *feats : torch.Tensor\n",
    "            Feature tensors to be combined. Must be broadcast-compatible\n",
    "            except for the concatenation dimension.\n",
    "        dim : int, optional\n",
    "            Dimension along which to concatenate the features (default: -1).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Concatenated feature tensor.\n",
    "        \"\"\"\n",
    "        feats = [feature.unsqueeze(-1) if feature.dim() == 1 else feature for feature in feats]\n",
    "        return torch.cat(feats, dim=dim)\n",
    "\n",
    "    def _get_file(self):\n",
    "        \"\"\"\n",
    "        Lazily opens the HDF5 file and keeps it open for reuse\n",
    "        to avoids repeatedly opening and closing the HDF5 file on every\n",
    "        __getitem__ call. Reduces I/O overhead.\n",
    "\n",
    "        \"\"\"\n",
    "        if self._f is None:\n",
    "            self._f = h5py.File(self.h5_path, \"r\")\n",
    "        return self._f\n",
    "\n",
    "    def get_fully_connected_edges(self, N):\n",
    "        \"\"\"\n",
    "        Returns the edge_index of a fully connected directed graph with N nodes,\n",
    "        excluding self-loops and caches the result for performance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        N : int\n",
    "            Number of nodes in the graph.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        edge_index : torch.Tensor\n",
    "            Edge index tensor \n",
    "        \"\"\"\n",
    "        if N not in self._edge_cache:\n",
    "            adj = torch.ones(N, N, dtype=torch.bool)\n",
    "            adj.fill_diagonal_(False)\n",
    "            self._edge_cache[N] = dense_to_sparse(adj)[0]\n",
    "\n",
    "        return self._edge_cache[N]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc2b9e9",
   "metadata": {},
   "source": [
    "<h1> Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "011d05d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 2])\n",
      "torch.Size([1, 1, 2])\n",
      "torch.Size([1, 1, 2])\n",
      "torch.Size([1, 1, 2])\n",
      "torch.Size([1, 1, 2])\n",
      "Total time: 0.005s\n",
      "Time per batch: 0.000997s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "dataset = h5Dataset(\"test.h5\")\n",
    "loader = DataLoader(dataset, batch_size=1)\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "for i, batch in enumerate(loader):\n",
    "    print(batch.shape)\n",
    "\n",
    "elapsed = time.perf_counter() - start\n",
    "print(f\"Total time: {elapsed:.3f}s\")\n",
    "print(f\"Time per batch: {elapsed / len(loader):.6f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eb786b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acoupipe_customFeatures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
