{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15fe7fd3",
   "metadata": {},
   "source": [
    "<h1> Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70bf09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import MessagePassing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d657419a",
   "metadata": {},
   "source": [
    "<h1> Message Passing Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2272f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNNLayer(MessagePassing):\n",
    "    \"\"\"\n",
    "    One message-passing block with edge features, mean aggregation (stable across N),\n",
    "    residual connection, and LayerNorm to reduce oversmoothing in fully-connected graphs.\n",
    "\n",
    "    Input/Output node dim stays constant: hidden_dim -> hidden_dim\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim: int, edge_dim: int, dropout: float = 0.0):\n",
    "        \n",
    "        super().__init__(aggr=\"mean\") # fully connected graph, so messages dont blow up with \"add\" aggregation\n",
    "\n",
    "        self.msg_mlp = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_dim + edge_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "        )\n",
    "\n",
    "        self.upd_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "        )\n",
    "\n",
    "        self.norm = nn.LayerNorm(hidden_dim) #helps with oversmoothing\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_attr: torch.Tensor) -> torch.Tensor:\n",
    "        # propagate: message passing + aggregation + update\n",
    "        out = self.propagate(edge_index=edge_index, x=x, edge_attr=edge_attr)\n",
    "        # residual helps with oversmoothing\n",
    "        return self.norm(x + out)\n",
    "\n",
    "    def message(self, x_i: torch.Tensor, x_j: torch.Tensor, edge_attr: torch.Tensor) -> torch.Tensor:\n",
    "        # x_i: target node features [E, H]\n",
    "        # x_j: source node features [E, H]\n",
    "        # edge_attr:             [E, E_dim]\n",
    "        msg_in = torch.cat([x_i, x_j, edge_attr], dim=-1)  # [E, 2H + E_dim]\n",
    "        return self.msg_mlp(msg_in)                        # [E, H]\n",
    "\n",
    "    def update(self, aggr_out: torch.Tensor, x: torch.Tensor) -> torch.Tensor:\n",
    "        # aggr_out: [N, H], x: [N, H]\n",
    "        upd_in = torch.cat([x, aggr_out], dim=-1)          # [N, 2H]\n",
    "        return self.upd_mlp(upd_in)                        # [N, H]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc19fb1",
   "metadata": {},
   "source": [
    "<h1> MPNN Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c87e714",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MicEncoderMPNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Full microphone embedding encoder:\n",
    "      node_in -> hidden_dim -> (L x MPNNLayer) -> out_dim\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_in_dim: int,\n",
    "        edge_in_dim: int,\n",
    "        hidden_dim: int = 128,\n",
    "        out_dim: int = 128,\n",
    "        num_layers: int = 2,\n",
    "        dropout: float = 0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # --- project node features to hidden dim\n",
    "        self.node_encoder = nn.Sequential(\n",
    "            nn.Linear(node_in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "        )\n",
    "\n",
    "        # --- multiple MPNN layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            MPNNLayer(hidden_dim=hidden_dim, edge_dim=edge_in_dim, dropout=dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # --- final projection to the token dim you want for cross-attention\n",
    "        self.node_head = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_attr: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x:         [N, node_in_dim]\n",
    "        edge_index:[2, E]\n",
    "        edge_attr: [E, edge_in_dim]\n",
    "        returns:   [N, out_dim] microphone embeddings (tokens)\n",
    "        \"\"\"\n",
    "        h = self.node_encoder(x)\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, edge_index, edge_attr)\n",
    "        return self.node_head(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2dd61f",
   "metadata": {},
   "source": [
    "<h1> Instantiating and Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24303a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example usage:\n",
    "model = MicEncoderMPNN(\n",
    "    node_in_dim=data.x.size(-1),\n",
    "    edge_in_dim=data.edge_attr.size(-1),\n",
    "    hidden_dim=128,\n",
    "    out_dim=128,\n",
    "    num_layers=2,  \n",
    "    dropout=0.1,\n",
    "    aggr=\"mean\",\n",
    ")\n",
    "\n",
    "mic_tokens = model(data.x, data.edge_index, data.edge_attr)  # [N, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b16438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Loop Example\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # Define optimizer.\n",
    "\n",
    "def train(data):\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out, h = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "    loss = criterion(out, data.y)  # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    return loss, h\n",
    "\n",
    "for epoch in range(1000):\n",
    "    loss, h = train(data)\n",
    "    if epoch % 100 == 0: print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f98f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acoupipe_customFeatures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
