{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ca0f55e",
   "metadata": {},
   "source": [
    "<h3> Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "456cab41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/acoupipe_customFeatures/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Data \n",
    "from torch_geometric.loader import DataLoader \n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "\n",
    "import h5py\n",
    "import math\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af4265a",
   "metadata": {},
   "source": [
    "<h1> Defining our custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7971e5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class h5Dataset(Dataset):\n",
    "    def __init__(self, h5_path):\n",
    "        self.h5_path = h5_path\n",
    "\n",
    "        with h5py.File(self.h5_path, \"r\") as f:\n",
    "            self.keys = list(f.keys())\n",
    "\n",
    "        self._edge_cache = {} # cache for fully connected edges to improve performance\n",
    "        self._f = None  # open file once \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # --- open file ---\n",
    "        f = self._get_file()\n",
    "\n",
    "        # --- load sample ---\n",
    "        sample = f[self.keys[index]]\n",
    "\n",
    "        # --- load raw features from sample ---\n",
    "        csm = torch.from_numpy(sample[\"csm\"][:]).squeeze() # (N, N), complex128\n",
    "        eigmode = torch.from_numpy(sample[\"eigmode\"][:]) # (N, N), complex128\n",
    "        loc = torch.from_numpy(sample[\"loc\"][:]) # (Dimensions, Num_Sources), float64\n",
    "        source_strength = torch.from_numpy(sample[\"source_strength_analytic\"][:]).squeeze(0) # (Num_Sources,), float64\n",
    "        \n",
    "        # --- define node features ---\n",
    "        coords = torch.from_numpy(sample[\"cartesian_coordinates\"][:]).T # (N, Dimensions), float64 \n",
    "        \n",
    "        theta = torch.atan2(coords[:, 1], coords[:, 0])\n",
    "        cos_theta = torch.cos(theta) # (N,), float64\n",
    "        sin_theta = torch.sin(theta) # (N,), float64\n",
    "\n",
    "        r = torch.sqrt(coords[:, 0]**2 + coords[:, 1]**2) # (N,), float64\n",
    "        r = r / (r.max() + 1e-8) # normalize radius  \n",
    "        \n",
    "        autopower = torch.diagonal(csm) # (N,), complex128\n",
    "        autopower_real = autopower.real\n",
    "        autopower_imag = autopower.imag\n",
    "\n",
    "        #TODO: implement positional encoding\n",
    "\n",
    "        # --- define adjacency--- #\n",
    "        node_index = torch.arange(coords.shape[0])\n",
    "        ii, jj = torch.meshgrid(node_index, node_index, indexing=\"ij\") \n",
    "        mask = (ii != jj) #remove self-loops\n",
    "        src = ii[mask].reshape(-1) \n",
    "        dst = jj[mask].reshape(-1)  \n",
    "\n",
    "        edge_index = torch.stack([src, dst], dim=0) # (2, E)\n",
    "\n",
    "        # --- define edge features ---\n",
    "        cross_spectra = csm[mask]  # (E, 1), complex128\n",
    "        cross_spectra_real = cross_spectra.real # (E, 1), float64\n",
    "        cross_spectra_imag = cross_spectra.imag # (E, 1), float64\n",
    "\n",
    "        dx = (coords[dst, 0] - coords[src, 0]).unsqueeze(-1)\n",
    "        dy = (coords[dst, 1] - coords[src, 1]).unsqueeze(-1)     \n",
    "        dist = torch.sqrt(dx**2 + dy**2 + 1e-8) # (E, 1), float64\n",
    "        \n",
    "        unit_direction_x = dx / dist # (E, 1), float64 \n",
    "        unit_direction_y = dy / dist # (E, 1), float64\n",
    "\n",
    "        cos_sim = (cos_theta[src] * cos_theta[dst] + sin_theta[src] * sin_theta[dst]) # (E, 1), float64, computed with trigonometric identity\n",
    "\n",
    "        #TODO: implement positional encoding\n",
    "\n",
    "\n",
    "        # --- build feature vectors ---\n",
    "\n",
    "        node_feat = self.build_feature(coords, r, cos_theta, sin_theta, autopower_real, autopower_imag, dim=1) # (N, F_node)\n",
    "        edge_attr = self.build_feature(cross_spectra_real,cross_spectra_imag, dist, unit_direction_x, unit_direction_y, cos_sim, dim=1)  # (E, F_edge)\n",
    "\n",
    "        # --- labels ---\n",
    "        loc_strongest_source = loc[:,torch.argmax(source_strength)]\n",
    "\n",
    "\n",
    "        # --- build PyG Data ---\n",
    "        data = Data(\n",
    "            x=node_feat,                 # (N, F_node)\n",
    "            edge_index=edge_index,       # (2, E)\n",
    "            edge_attr=edge_attr,         # (E, F_edge)\n",
    "            y=loc_strongest_source,      # label used by training loop\n",
    "        )\n",
    "\n",
    "        data.eigmode = eigmode\n",
    "\n",
    "        return cross_spectra_real, cross_spectra_imag\n",
    "    \n",
    "\n",
    "    #--- utility functions ---\n",
    "    def _get_file(self):\n",
    "        if self._f is None:\n",
    "            self._f = h5py.File(self.h5_path, \"r\")\n",
    "        return self._f\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def build_feature(*feats, dim=-1):\n",
    "        \"\"\"\n",
    "        Utility function to construct a feature tensor from multiple inputs.\n",
    "\n",
    "        If a tensor is 1D (shape: [N]), it is automatically expanded to\n",
    "        shape [N, 1] so that it can be concatenated with higher-dimensional\n",
    "        feature tensors.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        *feats : torch.Tensor\n",
    "            Feature tensors to be combined. Must be broadcast-compatible\n",
    "            except for the concatenation dimension.\n",
    "        dim : int, optional\n",
    "            Dimension along which to concatenate the features (default: -1).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Concatenated feature tensor.\n",
    "        \"\"\"\n",
    "        feats = [feature.unsqueeze(-1) if feature.dim() == 1 else feature for feature in feats]\n",
    "        return torch.cat(feats, dim=dim)\n",
    "\n",
    "\n",
    "    def get_fully_connected_edges(self, N):\n",
    "        \"\"\"\n",
    "        Returns the edge_index of a fully connected directed graph with N nodes,\n",
    "        excluding self-loops and caches the result for performance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        N : int\n",
    "            Number of nodes in the graph.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        edge_index : torch.Tensor\n",
    "            Edge index tensor \n",
    "        \"\"\"\n",
    "        if N not in self._edge_cache:\n",
    "            adj = torch.ones(N, N, dtype=torch.bool)\n",
    "            adj.fill_diagonal_(False)\n",
    "            self._edge_cache[N] = dense_to_sparse(adj)[0]\n",
    "\n",
    "        return self._edge_cache[N]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc2b9e9",
   "metadata": {},
   "source": [
    "<h1> Creating a dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "011d05d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'h5Dataset' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m loader = DataLoader(dataset, batch_size=\u001b[32m1\u001b[39m)\n\u001b[32m      6\u001b[39m start = time.perf_counter()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m elapsed = time.perf_counter() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/acoupipe_customFeatures/lib/python3.12/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/acoupipe_customFeatures/lib/python3.12/site-packages/torch/utils/data/dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/acoupipe_customFeatures/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 71\u001b[39m, in \u001b[36mh5Dataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     64\u001b[39m cos_sim = (cos_theta[src] * cos_theta[dst] + sin_theta[src] * sin_theta[dst]) \u001b[38;5;66;03m# (E, 1), float64, computed with trigonometric identity\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m#TODO: implement positional encoding\u001b[39;00m\n\u001b[32m     67\u001b[39m \n\u001b[32m     68\u001b[39m \n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# --- build feature vectors ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m node_feat = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos_theta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin_theta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautopower_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautopower_imag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (N, F_node)\u001b[39;00m\n\u001b[32m     72\u001b[39m edge_attr = \u001b[38;5;28mself\u001b[39m.build_feature(cross_spectra_real,cross_spectra_imag, dist, unit_direction_x, unit_direction_y, cos_sim, dim=\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (E, F_edge)\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# --- labels ---\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 119\u001b[39m, in \u001b[36mh5Dataset.build_feature\u001b[39m\u001b[34m(dim, *feats)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_feature\u001b[39m(*feats, dim=-\u001b[32m1\u001b[39m):\n\u001b[32m     99\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03m    Utility function to construct a feature tensor from multiple inputs.\u001b[39;00m\n\u001b[32m    101\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    117\u001b[39m \u001b[33;03m        Concatenated feature tensor.\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     feats = [f.unsqueeze(-\u001b[32m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdim\u001b[49m() == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m feats]\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(feats, dim=dim)\n",
      "\u001b[31mAttributeError\u001b[39m: 'h5Dataset' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "dataset = h5Dataset(\"test.h5\")\n",
    "loader = DataLoader(dataset, batch_size=1)\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "for i, batch in enumerate(loader):\n",
    "    print(batch[0])\n",
    "\n",
    "elapsed = time.perf_counter() - start\n",
    "print(f\"Total time: {elapsed:.3f}s\")\n",
    "print(f\"Time per batch: {elapsed / len(loader):.6f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "15ab921d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0.00041895799949998036\n",
      "64 0.00022091599930718075\n",
      "256 0.0003647920002549654\n",
      "1024 0.0012085000016668346\n"
     ]
    }
   ],
   "source": [
    "for N in [16, 64, 256, 1024]:\n",
    "    adj = torch.ones(N, N, dtype=torch.bool)\n",
    "    adj.fill_diagonal_(False)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    dense_to_sparse(adj)\n",
    "    elapsed = time.perf_counter() - start\n",
    "\n",
    "    print(N, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4fbac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acoupipe_customFeatures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
