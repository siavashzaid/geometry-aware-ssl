{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d0d197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from h5Dataset import h5Dataset\n",
    "from modules import MPNNLayer, MPNNTokenizer, SelfAttentionEncoder, PredictionHead\n",
    "from model import MPNNTransformerModel\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf16c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1 | loss = 0.053237\n",
      "Epoch   25 | loss = 0.013544\n",
      "Epoch   50 | loss = 0.012356\n",
      "Epoch   75 | loss = 0.011797\n",
      "Epoch  100 | loss = 0.011814\n",
      "Epoch  125 | loss = 0.008432\n",
      "Epoch  150 | loss = 0.006433\n",
      "Epoch  175 | loss = 0.005515\n",
      "Epoch  200 | loss = 0.003683\n",
      "Epoch  225 | loss = 0.003715\n",
      "Epoch  250 | loss = 0.003160\n",
      "Epoch  275 | loss = 0.003258\n",
      "Epoch  300 | loss = 0.000798\n",
      "Epoch  325 | loss = 0.000720\n",
      "Epoch  350 | loss = 0.000324\n",
      "Epoch  375 | loss = 0.000235\n",
      "Epoch  400 | loss = 0.000187\n",
      "Epoch  425 | loss = 0.000157\n",
      "Epoch  450 | loss = 0.000135\n",
      "Epoch  475 | loss = 0.000119\n",
      "Epoch  500 | loss = 0.000108\n",
      "\n",
      "Predictions vs targets:\n",
      "[00] pred=[0.06399404 0.26747346]  target=[[0.0637504  0.27527907]]\n",
      "[01] pred=[ 0.03137429 -0.06574981]  target=[[ 0.03151155 -0.06910084]]\n",
      "[02] pred=[ 0.25985107 -0.24152297]  target=[[ 0.26129934 -0.24150708]]\n",
      "[03] pred=[-0.01402315  0.1424833 ]  target=[[-0.01454815  0.1408742 ]]\n",
      "[04] pred=[-0.29331306  0.14965004]  target=[[-0.28629878  0.15405327]]\n",
      "[05] pred=[-0.2822484   0.20836231]  target=[[-0.28557602  0.19455917]]\n",
      "[06] pred=[0.23041126 0.1338386 ]  target=[[0.21992949 0.13799658]]\n",
      "[07] pred=[-0.2374852  0.279682 ]  target=[[-0.22682664  0.30383795]]\n",
      "[08] pred=[0.00848383 0.12140038]  target=[[0.00428969 0.11796549]]\n",
      "[09] pred=[-0.00648342 -0.00183219]  target=[[ 0.00596436 -0.0097244 ]]\n",
      "[10] pred=[-0.09234826 -0.17338222]  target=[[-0.08260332 -0.15429649]]\n",
      "[11] pred=[-0.04406099  0.09733538]  target=[[-0.04077311  0.09625879]]\n",
      "[12] pred=[ 0.17108005 -0.01927207]  target=[[ 0.17163995 -0.020958  ]]\n",
      "[13] pred=[-0.14489971 -0.3340848 ]  target=[[-0.14536427 -0.3341658 ]]\n",
      "[14] pred=[ 0.17439845 -0.07863314]  target=[[ 0.1739218  -0.07540922]]\n",
      "[15] pred=[ 0.12038761 -0.31312984]  target=[[ 0.12125795 -0.31386778]]\n",
      "[16] pred=[0.26701662 0.06299947]  target=[[0.27394906 0.05149376]]\n",
      "[17] pred=[ 0.05674877 -0.1560801 ]  target=[[ 0.05893723 -0.15768556]]\n",
      "[18] pred=[-0.06394401  0.06661827]  target=[[-0.08002059  0.08013394]]\n",
      "[19] pred=[-0.23131192 -0.31702316]  target=[[-0.23182662 -0.31611535]]\n",
      "[20] pred=[ 0.04533817 -0.02529796]  target=[[ 0.04314064 -0.0091474 ]]\n",
      "[21] pred=[-0.21595412  0.10082193]  target=[[-0.21718974  0.10007179]]\n",
      "[22] pred=[-0.14360905 -0.08005299]  target=[[-0.15660311 -0.07054469]]\n",
      "[23] pred=[0.18089378 0.11314835]  target=[[0.18256158 0.13644063]]\n",
      "[24] pred=[ 0.04849506 -0.21985334]  target=[[ 0.04266528 -0.21712722]]\n",
      "[25] pred=[-0.16308609 -0.04464871]  target=[[-0.16967599 -0.05030137]]\n",
      "[26] pred=[0.14334205 0.12063094]  target=[[0.138599   0.15153645]]\n",
      "[27] pred=[-0.17060742  0.08617464]  target=[[-0.16798405  0.08486   ]]\n",
      "[28] pred=[-0.07955298  0.03240404]  target=[[-0.07661296  0.02519329]]\n",
      "[29] pred=[-0.18805382 -0.2143234 ]  target=[[-0.18983716 -0.21881983]]\n",
      "[30] pred=[-0.01661732  0.43958   ]  target=[[-0.01784112  0.43952525]]\n",
      "[31] pred=[-0.10307261 -0.16411963]  target=[[-0.11629149 -0.19621392]]\n",
      "[32] pred=[ 0.16067931 -0.12219959]  target=[[ 0.15872175 -0.12587605]]\n",
      "[33] pred=[-0.13691658 -0.04872158]  target=[[-0.13029328 -0.05797008]]\n",
      "[34] pred=[-0.1527932  -0.07696162]  target=[[-0.15185934 -0.07274883]]\n",
      "[35] pred=[ 0.05111702 -0.16147214]  target=[[ 0.05060507 -0.16078793]]\n",
      "[36] pred=[ 0.09596894 -0.00758086]  target=[[ 0.10228128 -0.02938183]]\n",
      "[37] pred=[-0.1045543  -0.03730945]  target=[[-0.10582602 -0.03594827]]\n",
      "[38] pred=[-0.01343627 -0.16225004]  target=[[-0.00948752 -0.15915945]]\n",
      "[39] pred=[ 0.22910959 -0.05601324]  target=[[ 0.23836572 -0.05372366]]\n",
      "[40] pred=[-0.22895667 -0.26255795]  target=[[-0.22652367 -0.26074058]]\n",
      "[41] pred=[ 0.00885852 -0.00390555]  target=[[ 0.00788777 -0.00656841]]\n",
      "[42] pred=[-0.33332515 -0.01657987]  target=[[-0.33254567 -0.02873346]]\n",
      "[43] pred=[ 0.00848192 -0.328756  ]  target=[[ 0.00974224 -0.32789254]]\n",
      "[44] pred=[0.3030084  0.08635804]  target=[[0.30097574 0.09136516]]\n",
      "[45] pred=[-0.09759913 -0.14448598]  target=[[-0.09683662 -0.14698893]]\n",
      "[46] pred=[ 0.25811473 -0.00093072]  target=[[0.26075915 0.00605029]]\n",
      "[47] pred=[0.24819842 0.01093629]  target=[[0.24610285 0.0037387 ]]\n",
      "[48] pred=[-0.339106    0.10646977]  target=[[-0.35851353  0.10047796]]\n",
      "[49] pred=[-0.14704567 -0.12375529]  target=[[-0.1402203  -0.10573576]]\n",
      "[50] pred=[-0.06569859  0.04484428]  target=[[-0.05494808  0.05431987]]\n",
      "[51] pred=[-0.10165264 -0.13200212]  target=[[-0.1057008  -0.13006473]]\n",
      "[52] pred=[-0.22917932  0.0252549 ]  target=[[-0.21054526  0.02883739]]\n",
      "[53] pred=[-0.05532625 -0.01203348]  target=[[-0.05882196  0.00926739]]\n",
      "[54] pred=[-0.05400509 -0.20091903]  target=[[-0.0537852 -0.1996091]]\n",
      "[55] pred=[0.06251682 0.20625335]  target=[[0.05554394 0.20329913]]\n",
      "[56] pred=[-0.27103317 -0.07734181]  target=[[-0.27471852 -0.07617891]]\n",
      "[57] pred=[0.15533966 0.10493241]  target=[[0.15920873 0.09965578]]\n",
      "[58] pred=[ 0.3605632  -0.01830313]  target=[[ 0.35644   -0.0182947]]\n",
      "[59] pred=[0.11931705 0.08063631]  target=[[0.11457159 0.07998385]]\n",
      "[60] pred=[-0.30980384  0.28423464]  target=[[-0.31290305  0.27256173]]\n",
      "[61] pred=[0.22609481 0.42222184]  target=[[0.23226716 0.42289513]]\n",
      "[62] pred=[-0.34302393  0.02138566]  target=[[-0.33978346  0.03254929]]\n",
      "[63] pred=[-0.2379218   0.22429138]  target=[[-0.23702303  0.22607505]]\n",
      "[64] pred=[-0.0465501  -0.03895107]  target=[[-0.04943635 -0.03167411]]\n",
      "[65] pred=[-0.28116065  0.36836028]  target=[[-0.27964678  0.369026  ]]\n",
      "[66] pred=[0.13547677 0.06635951]  target=[[0.1279788  0.05650916]]\n",
      "[67] pred=[ 0.21402231 -0.14845636]  target=[[ 0.20876288 -0.14567009]]\n",
      "[68] pred=[0.10038035 0.09990776]  target=[[0.10427347 0.09768349]]\n",
      "[69] pred=[-0.10169714  0.09173699]  target=[[-0.09669659  0.08472237]]\n",
      "[70] pred=[0.08696059 0.18972263]  target=[[0.09137259 0.19545048]]\n",
      "[71] pred=[0.25324515 0.07945328]  target=[[0.25652644 0.07209346]]\n",
      "[72] pred=[-0.06496889 -0.09129904]  target=[[-0.06139472 -0.10327242]]\n",
      "[73] pred=[ 0.09029225 -0.21688247]  target=[[ 0.09401625 -0.22012693]]\n",
      "[74] pred=[ 0.2496056  -0.05438476]  target=[[ 0.26697907 -0.05852067]]\n",
      "[75] pred=[-0.05673876  0.09270262]  target=[[-0.06155634  0.08791418]]\n",
      "[76] pred=[ 0.1855647 -0.0500637]  target=[[ 0.17732109 -0.04633634]]\n",
      "[77] pred=[ 0.32666588 -0.06642963]  target=[[ 0.3246447  -0.06130649]]\n",
      "[78] pred=[0.1300534  0.08268017]  target=[[0.11889087 0.07745685]]\n",
      "[79] pred=[-0.04919838 -0.38693786]  target=[[-0.04993698 -0.3859418 ]]\n",
      "[80] pred=[-0.00797826 -0.0070273 ]  target=[[-0.00852012 -0.00258362]]\n",
      "[81] pred=[ 0.13405082 -0.02468537]  target=[[ 0.15045789 -0.02046215]]\n",
      "[82] pred=[ 0.0118248  -0.03480861]  target=[[ 0.00948533 -0.04759878]]\n",
      "[83] pred=[-0.18101731  0.08248428]  target=[[-0.17678314  0.07976846]]\n",
      "[84] pred=[-0.36911604  0.26206473]  target=[[-0.36964634  0.26344153]]\n",
      "[85] pred=[-0.01445808 -0.0121864 ]  target=[[-0.00943615 -0.02905401]]\n",
      "[86] pred=[-0.13807781 -0.14557907]  target=[[-0.13727775 -0.1496013 ]]\n",
      "[87] pred=[-0.0636456  -0.01368732]  target=[[-0.05939069 -0.01895204]]\n",
      "[88] pred=[0.07786974 0.09076111]  target=[[0.03104303 0.1355039 ]]\n",
      "[89] pred=[-0.00910035 -0.02320588]  target=[[-0.01546489 -0.01928374]]\n",
      "[90] pred=[-0.10704217 -0.18957433]  target=[[-0.10697766 -0.18521619]]\n",
      "[91] pred=[0.05849591 0.02249333]  target=[[0.05985807 0.02128263]]\n",
      "[92] pred=[-0.22167107 -0.1441884 ]  target=[[-0.22184056 -0.14354381]]\n",
      "[93] pred=[ 0.0900059  -0.16452792]  target=[[ 0.09025484 -0.16440605]]\n",
      "[94] pred=[0.08500132 0.08929395]  target=[[0.13933782 0.05220385]]\n",
      "[95] pred=[-0.06267431  0.06673304]  target=[[-0.07065611  0.07613002]]\n",
      "[96] pred=[0.23947692 0.17081171]  target=[[0.23305096 0.1633327 ]]\n",
      "[97] pred=[0.21528512 0.15806535]  target=[[0.22735275 0.15119112]]\n",
      "[98] pred=[-0.30429566 -0.21143833]  target=[[-0.30355534 -0.20852834]]\n",
      "[99] pred=[0.33251688 0.15681285]  target=[[0.32768074 0.16117927]]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "   \n",
    "    torch.manual_seed(0)\n",
    "    #Using GPU 3, check if available before running\n",
    "    device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load Dataset\n",
    "    h5_path = \"../data/samples/100samples.h5\"  # <- CHANGE THIS\n",
    "    ds = h5Dataset(h5_path)\n",
    "\n",
    "    loader = DataLoader(ds, batch_size=10)\n",
    "\n",
    "    # take feature dims from one sample\n",
    "    sample0 = ds[0]\n",
    "    node_in_dim = sample0.x.shape[-1]\n",
    "    edge_in_dim = sample0.edge_attr.shape[-1]\n",
    "\n",
    "    # Build model\n",
    "    model = MPNNTransformerModel(\n",
    "        node_in_dim=node_in_dim,\n",
    "        edge_in_dim=edge_in_dim,\n",
    "        num_output_sources=1,  \n",
    "    ).to(device)\n",
    "\n",
    "    # Optimizer, loss, scheduler\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.0)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer,\n",
    "        step_size=25,   # every 10 epochs\n",
    "        gamma=0.8      # multiply LR by 0.8\n",
    "    )\n",
    "\n",
    "    # 6) Train loop (overfit)\n",
    "    num_epochs = 500  # usually enough to see memorization\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "\n",
    "            pred = model.forward_from_data(data)  # expected shape: [I, 2] with I=1\n",
    "            \n",
    "            target = data.y\n",
    "\n",
    "            loss = F.mse_loss(pred, target)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            \n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        avg_loss = running_loss / len(loader)\n",
    "        \n",
    "        #print occasionally\n",
    "        if epoch % 25 == 0 or epoch == 1:\n",
    "            print(f\"Epoch {epoch:4d} | loss = {avg_loss:.6f}\")\n",
    "\n",
    "        if avg_loss < 1e-6:\n",
    "            print(f\"Early stopping at epoch {epoch} with loss {avg_loss:.6f}\")\n",
    "            break\n",
    "\n",
    "    #Quick evaluation on the same samples\n",
    "\n",
    "    model.eval()\n",
    "    print(\"\\nPredictions vs targets:\")\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(ds):\n",
    "            data = data.to(device)\n",
    "            pred = model.forward_from_data(data)  # [1,2]\n",
    "            target = data.y\n",
    "            if target.dim() == 1:\n",
    "                target = target.unsqueeze(0)\n",
    "            if target.shape[-1] == 3:\n",
    "                target = target[:, :2]\n",
    "\n",
    "            print(f\"[{i:02d}] pred={pred.squeeze(0).cpu().numpy()}  target={target.squeeze(0).cpu().numpy()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94c00ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acoupipe_customFeatures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
